{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer,AdagradOptimizer\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "from autoencoder import Autoencoder\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "import os\n",
    "from EMCost import *\n",
    "\n",
    "def fidelity(X,trainer,input_state,n_qubit_auto,n_qubit_trash):\n",
    "    def _fidelity(w):\n",
    "        output_dms =np.array([trace_out(trainer(w,x),range(n_qubit_trash, n_qubit_trash+n_qubit_auto)) for x in X], requires_grad=True)\n",
    "        fid=[1-qml.math.fidelity(a,b) for a,b in zip(output_dms,input_state)]\n",
    "        return np.mean(np.array(fid))\n",
    "    return _fidelity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder_autodecoder():\n",
    "   \n",
    "\n",
    "    def __init__(self,n_qubit_autoencoder,n_qubit_trash,device,stages=['c6','c11'],seed=None):\n",
    "\n",
    "\n",
    "        if seed is None:\n",
    "            seed=random.random()\n",
    "            self.__seed=seed\n",
    "        else:\n",
    "            self.__seed=seed\n",
    "        random.seed(seed)\n",
    "        if n_qubit_autoencoder not in [4,8]:\n",
    "            raise Exception('either 4 or 8 qubit with this state prep')\n",
    "\n",
    "        self.__layers=1\n",
    "        self.__n_qubit_auto = n_qubit_autoencoder\n",
    "        self.__n_qubit_trash = n_qubit_trash\n",
    "        self.__n_qubit=n_qubit_autoencoder+n_qubit_trash\n",
    "        self.__dvc=device\n",
    "        self.__stages = stages\n",
    "        self.__setup()\n",
    "\n",
    "        self.__num_params= sum([self.__circuits[cir]['n_par'](n_qubit_autoencoder) for cir in stages])\n",
    "        self.__num_params_stages= [self.__circuits[cir]['n_par'](n_qubit_autoencoder) for cir in stages]\n",
    "        self.__set_weights =None\n",
    "        \n",
    "        #set parameter to random values for the first stage and 0 to all the following\n",
    "        self.__wq=[np.array([random.uniform(0, np.pi) for _ in range(self.__num_params_stages[0])]+[0]*(self.__num_params-self.__num_params_stages[0]), requires_grad=True)]\n",
    "        # print(f'the device has {len(device.wires)} qubits')\n",
    "    \n",
    "\n",
    "    def original_auto(self,qb,parameter,start):\n",
    "        for i in range(start,qb+start):\n",
    "            qml.RX(parameter[i-start],wires=i)\n",
    "        for i in range(start,qb+start):\n",
    "            qml.RZ(parameter[i-start +qb],wires=i)\n",
    "        pindex=0\n",
    "        for j in range(start,qb+start):\n",
    "            for i in range(start,qb+start):\n",
    "                if j != i:\n",
    "                    qml.CRX(parameter[pindex +2*qb],wires=[j,i])\n",
    "                    pindex-=-1\n",
    "        for i in range(start,qb+start):\n",
    "            qml.RX(parameter[i-start+2*qb+qb*(qb-1)],wires=i)\n",
    "        for i in range(start,qb+start):\n",
    "            qml.RZ(parameter[i-start+3*qb+qb*(qb-1)],wires=i)\n",
    "\n",
    "    def __setup(self):\n",
    "        self.__circuits = {\n",
    "            'c6' : {'func':self.c6ansatz,\n",
    "                    'n_par':lambda q: q**2 +3*q,\n",
    "            },\n",
    "            'c11' :{'func':self.c11ansatz,\n",
    "                    'n_par':lambda q: (q*4 -4)*self.__layers,\n",
    "            },\n",
    "            'isin' : {'func':self.create_ising_state,\n",
    "            'n_par': lambda q : 0\n",
    "            }\n",
    "        }\n",
    "        self.__losses={\n",
    "            'fidelity': {'func':fidelity},\n",
    "            'EMdistance': {'func': cost_fn_EM}\n",
    "\n",
    "        }\n",
    "        self.__train_loss={}\n",
    "        self.__val_loss= {}\n",
    "        self.__sp = self.__circuits['isin']['func']\n",
    "\n",
    "        self.__loss= self.__losses['fidelity']['func']\n",
    "        system_size_x = 1\n",
    "        system_size_y = self.__n_qubit_auto\n",
    "        system_lattice = \"chain\"\n",
    "        system_periodicity = \"closed\"\n",
    "\n",
    "        n_wires =self.__n_qubit_auto\n",
    "\n",
    "        class dset:\n",
    "            sysname = None\n",
    "            xlen = 0\n",
    "            ylen = 0\n",
    "            tuning_parameter_name = None\n",
    "            order_parameter_name = None\n",
    "            lattice = None\n",
    "            periodicity = None\n",
    "            tuning_parameters = []\n",
    "\n",
    "        Ising_dataset = dset()\n",
    "        Ising_dataset.sysname = \"Ising\"\n",
    "        Ising_dataset.xlen = system_size_x\n",
    "        Ising_dataset.ylen = system_size_y\n",
    "        Ising_dataset.lattice = system_lattice\n",
    "        Ising_dataset.periodicity = system_periodicity\n",
    "        Ising_dataset.tuning_parameter_name = \"h\"\n",
    "        Ising_dataset.order_parameter_name = \"mz\"\n",
    "        current_dataset = Ising_dataset\n",
    "\n",
    "        self.__data = qml.data.load(\"qspin\", \n",
    "                            sysname=current_dataset.sysname, \n",
    "                            periodicity=current_dataset.periodicity, \n",
    "                            lattice=current_dataset.lattice, \n",
    "                            layout=(current_dataset.xlen, current_dataset.ylen))[0]\n",
    "\n",
    "        current_dataset.tuning_parameters = self.__data.parameters\n",
    "\n",
    "    def get_input_state(self,p):\n",
    "        return np.matmul( np.matrix(np.conjugate(self.__data.ground_states[p])).T, np.matrix(self.__data.ground_states[p]) )\n",
    "\n",
    "    def create_ising_state(self,p,start):\n",
    "        dm1 = np.matmul( np.matrix(np.conjugate(self.__data.ground_states[p])).T, np.matrix(self.__data.ground_states[p]) )\n",
    "        qml.QubitDensityMatrix(dm1, wires=range(self.__n_qubit_auto))\n",
    "\n",
    "    \n",
    "\n",
    "    def c6ansatz(self,param,start=0):\n",
    "        self.original_auto(self.__n_qubit_auto,param,start=start)\n",
    "\n",
    "    def create_circ(self,param,p,start=0):\n",
    "        self.__sp(p,0)\n",
    "        qml.Barrier()\n",
    "        self.create_encoder(param,start)\n",
    "        qml.Barrier()\n",
    "        self.create_decoder(param,start)\n",
    "\n",
    "\n",
    "    def create_encoder(self,params,start=0):\n",
    "        for stage,a in enumerate(self.__stages):\n",
    "            stage_params = (sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage)]),sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage+1)]))\n",
    "\n",
    "            self.__circuits[a]['func'](params[stage_params[0]:stage_params[1]],start)\n",
    "            \n",
    "    def create_decoder(self,params,start=0):\n",
    "        wire_map=dict(zip(list(range(self.__n_qubit_trash)),list(range(self.__n_qubit_auto,self.__n_qubit))))\n",
    "\n",
    "        def f():\n",
    "            for stage,a in enumerate(self.__stages):\n",
    "                stage_params = (sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage)]),sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage+1)]))\n",
    "                self.__circuits[a]['func'](params[stage_params[0]:stage_params[1]],start)\n",
    "        qml.adjoint(qml.map_wires(f, wire_map))()\n",
    "\n",
    "\n",
    "    def set_layers(self,layers):\n",
    "        self.__layers = layers\n",
    "        self.__num_params=sum([self.__circuits[cir]['n_par'](self.__n_qubit_auto) for cir in self.__stages])\n",
    "        self.__num_params_stages= [self.__circuits[cir]['n_par'](self.__n_qubit_auto) for cir in self.__stages]\n",
    "        random.seed(self.__seed)\n",
    "        self.__wq=[np.array([random.uniform(0, np.pi) for _ in range(self.__num_params_stages[0])]+[0]*(self.__num_params-self.__num_params_stages[0]), requires_grad=True)]\n",
    "\n",
    "    def c11(self,parameter,qb,start):\n",
    "        current_par =0\n",
    "        for i in range(start,qb//2+start):\n",
    "            qml.RY(parameter[current_par],wires=(i-start)*2+start)\n",
    "            current_par-=-1\n",
    "            qml.RY(parameter[current_par],wires=(i-start)*2+start+1)\n",
    "            current_par-=-1\n",
    "\n",
    "        for i in range(start,qb//2+start):\n",
    "            qml.RZ(parameter[current_par],wires=(i-start)*2+start)\n",
    "            current_par-=-1\n",
    "            qml.RZ(parameter[current_par],wires=(i-start)*2+start+1)\n",
    "            current_par-=-1\n",
    "\n",
    "        for i in range(start,qb//2+start):\n",
    "            qml.CNOT([(i-start)*2+start+1,(i-start)*2+start])\n",
    "\n",
    "        qml.Barrier()\n",
    "        for i in range(start,(qb-1)//2+start):        \n",
    "            qml.RY(parameter[current_par],wires=(i-start)*2+start+1)\n",
    "            current_par-=-1\n",
    "            qml.RY(parameter[current_par],wires=(i-start)*2+start+2)\n",
    "            current_par-=-1\n",
    "\n",
    "        for i in range(start,(qb-1)//2+start):   \n",
    "            qml.RZ(parameter[current_par],wires=(i-start)*2+start+1)\n",
    "            current_par-=-1\n",
    "            qml.RZ(parameter[current_par],wires=(i-start)*2+start+2)\n",
    "            current_par-=-1\n",
    "\n",
    "\n",
    "        for i in range(start,(qb-1)//2+start):\n",
    "            qml.CNOT([(i-start)*2+start+2,(i-start)*2+start+1])\n",
    "        qml.Barrier()\n",
    "\n",
    "    def c11ansatz(self,param,start):\n",
    "        parperlay = 4*self.__n_qubit_auto-4\n",
    "        for l in range(self.__layers):\n",
    "            self.c11(param[parperlay*l:parperlay*(l+1)],self.__n_qubit_auto,start) \n",
    "            qml.Barrier()\n",
    "\n",
    "    def plot_cirq(self):\n",
    "\n",
    "        @qml.qnode(self.__dvc)\n",
    "        def trainer(param,p):\n",
    "            self.create_circ(param,p)\n",
    "        fig, ax = qml.draw_mpl(trainer)(self.__wq[-1],.5)\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, X , opt,epochs,batch_size=None,warm_weights=None, val_split=0.0):\n",
    "        train_loss = []   \n",
    "        val_loss = [0]\n",
    "\n",
    "        X_train = X[0:int(np.floor(len(X)*(1-val_split)))]\n",
    "        X_val = X[int(np.floor(len(X)*(1-val_split))):]\n",
    "        if batch_size is None:\n",
    "            batch_size=len(X)\n",
    "        if warm_weights is not None:\n",
    "            if len(warm_weights)!= self.__num_params:\n",
    "                raise ValueError(f'The weights for the warm start should have length {self.__num_params}, but {len(warm_weights)} where found.')\n",
    "            self.__wq[-1]=warm_weights\n",
    "        if type(epochs) == int:\n",
    "            epochs = [epochs]+[0]*(len(self.__stages)-1)\n",
    "        if len(epochs)>len(self.__stages):\n",
    "            raise ValueError(f'The number of stage epochs are more than the number of stages')\n",
    "        @qml.qnode(self.__dvc,diff_method='best')\n",
    "        def trainer(param,p):\n",
    "            self.create_circ(param,p)\n",
    "            return qml.state()\n",
    "        \n",
    "        for stage,stage_epoch in enumerate(epochs):\n",
    "            stage_params = (sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage)]),sum([self.__circuits[self.__stages[a]]['n_par'](self.__n_qubit_auto) for a in range(stage+1)]))\n",
    "            opt.reset()\n",
    "            for epoch in range(stage_epoch):\n",
    "                batch_loss=[]\n",
    "                for i, X_batch in enumerate([X_train[i:i + batch_size] for i in range(0, len(X_train), batch_size)]):\n",
    "                    loss_function = self.__loss(X_batch,trainer,[self.get_input_state(x) for x in X_batch],self.__n_qubit_auto,self.__n_qubit_trash)\n",
    "                    weights, loss_value = opt.step_and_cost(loss_function, self.__wq[-1][stage_params[0]:stage_params[1]])\n",
    "                    batch_loss.append(loss_value)\n",
    "                    print(f'\\rStage: {stage}, \\tEpoch {epoch+1}, \\tBatch:{i}, \\tTrain Loss = {np.mean(batch_loss):.6f}, \\tVal Loss = {val_loss[-1]:.6f}',end='')\n",
    "                self.__wq.append(np.concatenate([self.__wq[-1][:stage_params[0]], weights, [0]*(self.__num_params-stage_params[1])], axis=0))\n",
    "                val_l=self.__loss(X_val,trainer,[self.get_input_state(x) for x in X_val],self.__n_qubit_auto,self.__n_qubit_trash) \n",
    "                val_loss.append(val_l(self.__wq[-1][stage_params[0]:stage_params[1]]))\n",
    "                train_loss.append(np.average(batch_loss,weights=[len(X_batch) for X_batch in [X_train[i:i + batch_size] for i in range(0, len(X_train), batch_size)]]))\n",
    "                if epoch > 5 and np.mean(val_loss[-3:])<0.001:\n",
    "                    print('\\nEarly stop')\n",
    "                    break\n",
    "\n",
    "        try:\n",
    "            console_size = os.get_terminal_size()\n",
    "        except OSError:\n",
    "            console_size = 50\n",
    "        print('\\n')\n",
    "        print('-'*console_size)\n",
    "        self.__train_loss=train_loss\n",
    "        self.__val_loss=val_loss[1:]\n",
    "        return train_loss,val_loss[1:], self.__wq.copy()\n",
    "\n",
    "    def best_params(self):\n",
    "        return self.__wq[np.argmin(self.__val_loss)+1] \n",
    "\n",
    "    def get_cirq(self,wire):\n",
    "        if self.__set_weights is None:\n",
    "            self.create_encoder(self.best_params(),wire)\n",
    "        else:\n",
    "            self.create_encoder(self.__set_weights,wire)\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        custom_palette =['#EABFCB','#C191A1','#A4508B','#5F0A87','#2F004F','#120021',]\n",
    "        sns.set_palette(custom_palette)  \n",
    "\n",
    "        plt.set_cmap\n",
    "        plt.plot(list(range(len(self.__train_loss))),self.__train_loss, label='train loss')\n",
    "        plt.plot(list(range(len(self.__val_loss))),self.__val_loss, label='val loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    def plot_weights(self):\n",
    "        i=0\n",
    "        for a in np.array(self.__wq).T:\n",
    "            plt.plot(range(len(a)),a,label=[i])\n",
    "            i-=-1\n",
    "        plt.legend()\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.__train_loss,self.__val_loss\n",
    "    \n",
    "    def get_num_par(self):\n",
    "        return self.__num_params\n",
    "    \n",
    "    def set_weights(self,param):\n",
    "        self.__set_weights= param\n",
    "    \n",
    "    def load(self,path):\n",
    "        self.__set_weights=np.load(path+'/weights.npy')\n",
    "        self.__train_loss=np.load(path+'/train_loss.npy')\n",
    "        self.__val_loss=np.load(path+'/val_loss.npy')\n",
    "\n",
    "    def get_current_loss(self,X):\n",
    "        @qml.qnode(self.__dvc,diff_method='adjoint')\n",
    "        def trainer(param,p):\n",
    "            self.create_circ(param,p)\n",
    "            return qml.probs(list(range(self.__n_qubit_trash)))\n",
    "        def loss_function():\n",
    "            if self.__set_weights is not None:\n",
    "                W=self.__set_weights\n",
    "            else:\n",
    "                W =self.__wq[-1]\n",
    "            pred =np.array([1-trainer(W,x)[0] for x in X], requires_grad=True)\n",
    "            current_loss = pred.mean()\n",
    "            return current_loss\n",
    "        return loss_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trash_qubit=2\n",
    "n_qubit_autoencoder=4\n",
    "n_qubit=n_qubit_autoencoder+n_trash_qubit\n",
    "dvc = qml.device('default.mixed', wires=n_qubit, shots=None)\n",
    "\n",
    "ae = Autoencoder_autodecoder(n_qubit_autoencoder,n_trash_qubit,dvc,stages=['c11'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trace_out(density_matrix, keep):\n",
    "    \"\"\"\n",
    "    Partially traces out the subsystems in `density_matrix` except those specified in `keep`.\n",
    "    \n",
    "    Parameters:\n",
    "    - density_matrix: Full density matrix as a 2D NumPy or PennyLane array.\n",
    "    - keep: List of qubits to keep after the partial trace.\n",
    "    \n",
    "    Returns:\n",
    "    - Reduced density matrix as a 2D NumPy or PennyLane array.\n",
    "    \"\"\"\n",
    "    num_qubits = int(qml.math.log2(density_matrix.shape[0]))  # Number of qubits based on density matrix dimensions.\n",
    "    if set(keep) - set(range(num_qubits)):\n",
    "        raise ValueError(\"Qubits to keep must be within the range of total qubits.\")\n",
    "\n",
    "    # Reshape density matrix to a multi-dimensional tensor (4 dimensions per qubit for matrix elements).\n",
    "    density_matrix = qml.math.reshape(density_matrix, [2] * (2 * num_qubits))\n",
    "    \n",
    "    # Define indices to keep after partial trace\n",
    "    keep_indices = list(keep) + [num_qubits + i for i in keep]  # Keep both row and column indices\n",
    "    trace_indices = [i for i in range(2 * num_qubits) if i not in keep_indices]\n",
    "\n",
    "    # Perform partial trace by summing out unwanted indices.\n",
    "    reduced_density_matrix = qml.math.tensordot(\n",
    "        density_matrix,\n",
    "        qml.math.ones([2] * len(trace_indices)),  # Tensor to trace out unwanted indices\n",
    "        axes=(trace_indices, list(range(len(trace_indices))))\n",
    "    )\n",
    "\n",
    "    # Reshape to final density matrix form with dimensions based on the qubits kept\n",
    "    final_dim = 2 ** len(keep)\n",
    "    return qml.math.reshape(reduced_density_matrix, (final_dim, final_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ArrayBox'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(X)\n\u001b[0;32m      4\u001b[0m epochs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m37\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mval_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.33\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 257\u001b[0m, in \u001b[0;36mAutoencoder_autodecoder.train\u001b[1;34m(self, X, opt, epochs, batch_size, warm_weights, val_split)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, X_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([X_train[i:i \u001b[38;5;241m+\u001b[39m batch_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_train), batch_size)]):\n\u001b[0;32m    256\u001b[0m     loss_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__loss(X_batch,trainer,[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_input_state(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_batch],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__n_qubit_auto,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__n_qubit_trash)\n\u001b[1;32m--> 257\u001b[0m     weights, loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstage_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstage_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m     batch_loss\u001b[38;5;241m.\u001b[39mappend(loss_value)\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mStage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mBatch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(batch_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mVal Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:59\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    objective function value prior to the step.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     g, forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\pennylane\\optimize\\gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[1;32m--> 117\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\pennylane\\_grad.py:120\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[1;32m--> 120\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\pennylane\\_grad.py:138\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[0;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\autograd\\core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[0;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[1;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\autograd\\tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(start_node, fun, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[1;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\autograd\\wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mfidelity.<locals>._fidelity\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate fidelity and ensure values are clamped to [0, 1]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m fid \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mclip(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfidelity(a, b), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(output_dms, input_state)]\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mmaximum(\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\autoray\\autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m choose_backend(fn, \u001b[38;5;241m*\u001b[39margs, like\u001b[38;5;241m=\u001b[39mlike, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_lib_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3433\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orazi\\anaconda3\\envs\\phd\\Lib\\site-packages\\numpy\\core\\_methods.py:190\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    188\u001b[0m         ret \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret \u001b[38;5;241m/\u001b[39m rcount\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "opt=AdamOptimizer(stepsize=.2)\n",
    "X=list(range(100))\n",
    "random.shuffle(X)\n",
    "epochs=[37]\n",
    "\n",
    "ae.train(X,opt,epochs,50,val_split=.33)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.99795586e-01+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j,  1.02030269e-04+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j,  1.02030269e-04+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          4.99795586e-01+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [ 2.04018889e-04+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j,  4.16492317e-08+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j,  4.16492317e-08+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          2.04018889e-04+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [ 1.02030269e-04+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j,  2.08288671e-08+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j,  2.08288671e-08+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          1.02030269e-04+0.j],\n",
       "        [ 2.04018889e-04+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j,  4.16492317e-08+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j,  4.16492317e-08+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          2.04018889e-04+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567752e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567752e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [ 2.04018889e-04+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j,  4.16492317e-08+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j,  4.16492317e-08+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          2.04018889e-04+0.j],\n",
       "        [ 1.02030269e-04+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j,  2.08288671e-08+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j,  2.08288671e-08+0.j, -1.03123944e-06+0.j,\n",
       "          4.16492317e-08+0.j, -1.03123944e-06+0.j, -1.03123944e-06+0.j,\n",
       "          1.02030269e-04+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567752e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567752e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [ 2.04018889e-04+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j,  4.16492317e-08+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j,  4.16492317e-08+0.j, -2.06205793e-06+0.j,\n",
       "          8.32814620e-08+0.j, -2.06205793e-06+0.j, -2.06205793e-06+0.j,\n",
       "          2.04018889e-04+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567752e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567752e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [-5.05152956e-03+0.j,  5.10567753e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567753e-05+0.j, -1.03123944e-06+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567753e-05+0.j,\n",
       "         -2.06205793e-06+0.j, -1.03123944e-06+0.j,  5.10567752e-05+0.j,\n",
       "         -2.06205793e-06+0.j,  5.10567752e-05+0.j,  5.10567752e-05+0.j,\n",
       "         -5.05152956e-03+0.j],\n",
       "        [ 4.99795586e-01+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j,  1.02030269e-04+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j,  1.02030269e-04+0.j, -5.05152956e-03+0.j,\n",
       "          2.04018889e-04+0.j, -5.05152956e-03+0.j, -5.05152956e-03+0.j,\n",
       "          4.99795585e-01+0.j]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=get_data(4)\n",
    "dm1 = np.matmul( np.matrix(np.conjugate(data.ground_states[1])).T, np.matrix(data.ground_states[1]) )\n",
    "dm1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
