{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer,AdagradOptimizer\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "from autoencoder import Autoencoder\n",
    "from autoencoder2 import Autoencoder_c11\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os \n",
    "from autoencoder3 import Autoencoder_composite\n",
    "from autoencoder5 import Autoencoder_autodecoder\n",
    "import time\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "import os\n",
    "from EMCost import *\n",
    "from pennylane.math import reduce_dm\n",
    "from autoencoder6 import JAxutoencoder\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import optax \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette =[\n",
    "    # '#C24AA2','#D6518F',\n",
    "    '#EC5A77','#F57C73','#F69C6D','#F6BC66']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_qubit_autoencoder=[8]\n",
    "range_batches = [20,50,100]\n",
    "seed=42\n",
    "epochs=100 \n",
    "n=100\n",
    "stepsize=.2\n",
    "opt = optax.adam(stepsize)\n",
    "# X=np.random.rand(n)*np.pi/2\n",
    "\n",
    "X=list(range(n))\n",
    "random.shuffle(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AE with 8 input qubit and 2 trash qubit in batches of 20\n",
      "Epoch 1, \tBatch:0, \tTrain Loss = 0.898294, \tVal Loss = 0.000000"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: Buffer Definition Event: Error preparing computation: %sOut of memory allocating 63032027800 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m ae\u001b[38;5;241m.\u001b[39mset_layers(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     21\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 22\u001b[0m \u001b[43mae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     25\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(folder)\n",
      "File \u001b[1;32m\\\\gess-fs.d.ethz.ch\\home$\\forazi\\Desktop\\multidestructiveSWAP\\autoencoder6.py:198\u001b[0m, in \u001b[0;36mJAxutoencoder.train\u001b[1;34m(self, X, opt, epochs, batch_size, warm_weights, val_split)\u001b[0m\n\u001b[0;32m    196\u001b[0m     weights, opt_state, loss_value \u001b[38;5;241m=\u001b[39m train_step(weights, opt_state, X_batch)\n\u001b[0;32m    197\u001b[0m     batch_loss\u001b[38;5;241m.\u001b[39mappend(loss_value)\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mBatch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mVal Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wq\u001b[38;5;241m.\u001b[39mappend(weights)\n\u001b[0;32m    200\u001b[0m val_l\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__loss(X_val,trainer,X_val,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__n_qubit_auto,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__n_qubit_trash) \n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\pennylane\\numpy\\wrapper.py:117\u001b[0m, in \u001b[0;36mtensor_wrapper.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m         tensor_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39many([i\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tensor_args])\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# evaluate the original object\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, _np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# only if the output of the object is a ndarray,\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# then convert to a PennyLane tensor\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     res \u001b[38;5;241m=\u001b[39m tensor(res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\autograd\\tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\jax\\_src\\array.py:429\u001b[0m, in \u001b[0;36mArrayImpl.__array__\u001b[1;34m(self, dtype, context, copy)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    427\u001b[0m   \u001b[38;5;66;03m# copy argument is supported by np.asarray starting in numpy 2.0\u001b[39;00m\n\u001b[0;32m    428\u001b[0m   kwds \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m: copy}\n\u001b[1;32m--> 429\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\jax\\_src\\profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mc:\\Users\\forazi\\.conda\\envs\\forazi\\Lib\\site-packages\\jax\\_src\\array.py:628\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[1;32m--> 628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[1;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: Buffer Definition Event: Error preparing computation: %sOut of memory allocating 63032027800 bytes."
     ]
    }
   ],
   "source": [
    "for n_qubit_autoencoder in range_qubit_autoencoder:\n",
    "    def get_input_state(p):\n",
    "        data=get_data(n_qubit_autoencoder)\n",
    "        return jnp.outer(data.ground_states[p], data.ground_states[p].conj())\n",
    "    X=[get_input_state(x) for x in X]\n",
    "\n",
    "    for n_trash_qubit in range(2,n_qubit_autoencoder):\n",
    "        train_batch_losses={}\n",
    "        val_batch_losses={}\n",
    "        batch_times={}\n",
    "        batch_epochs={}\n",
    "        img_folder=f'runs/run_{n_qubit_autoencoder}to{n_qubit_autoencoder-n_trash_qubit}'\n",
    "        os.makedirs(img_folder,exist_ok=True)\n",
    "        for batch_size in range_batches:\n",
    "            folder=img_folder+f'/{batch_size}'\n",
    "            print(f\"Running AE with {n_qubit_autoencoder} input qubit and {n_trash_qubit} trash qubit in batches of {batch_size}\")\n",
    "            n_qubit=n_qubit_autoencoder+n_trash_qubit\n",
    "            dvc = qml.device('default.mixed', wires=n_qubit, shots=None)\n",
    "            ae = JAxutoencoder(n_qubit_autoencoder,n_trash_qubit,dvc,'c11')\n",
    "            ae.set_layers(3)\n",
    "            start_time = time.time()\n",
    "            ae.train(X,opt,epochs,batch_size,val_split=.20)\n",
    "            end_time = time.time()\n",
    "\n",
    "            os.makedirs(folder)\n",
    "            train_loss,val_loss=ae.get_loss()\n",
    "            train_batch_losses[batch_size]=train_loss\n",
    "            val_batch_losses[batch_size]=val_loss\n",
    "            batch_times[batch_size]=end_time-start_time\n",
    "            batch_epochs[batch_size]=ae.get_final_epoch()\n",
    "            weights=ae.best_params()\n",
    "            np.save(folder+'/loss_train',np.array(train_loss))            \n",
    "            np.save(folder+'/loss_val',np.array(val_loss))            \n",
    "            np.save(folder+'/weights',np.array(weights))\n",
    "\n",
    "        # Min loss\n",
    "        min_val_found= {a:min(val_batch_losses[a]) for a in range_batches }\n",
    "        min_train_found= {a:min(train_batch_losses[a]) for a in range_batches }\n",
    "        min_loss,rank =get_min_loss_fid_ising(X,n_qubit_autoencoder,n_trash_qubit)\n",
    "\n",
    "        # Figure\n",
    "        plt.figure()\n",
    "        sns.set_palette(custom_palette)  \n",
    "        for a,b,c,d in zip(list(train_batch_losses.values()),list(val_batch_losses.values()),range_batches,custom_palette):\n",
    "            sns.lineplot(x=range(len(a)),y=a,label=f'train_{c}',color=d)\n",
    "            sns.lineplot(x=range(len(b)),y=[l.item() for l in b],label=f'val_{c}', color=d,linestyle=':')\n",
    "        plt.legend(title='Batch size')\n",
    "        # if len(epochs)>1:\n",
    "        #     plt.vlines(epochs[:-1],0,1,color='#C24AA2',linestyle='--')\n",
    "        #     plt.text(epochs[-1]-0.02, y=0.85, fontsize='medium', s=f'stage\\nchange', color='#973C7F', ha='center', va='center')\n",
    "\n",
    "        plt.hlines(min_loss,0,np.max(list(batch_epochs.values()))-1,color='#773344',linestyle='--')\n",
    "        plt.text(x=np.max(list(batch_epochs.values()))//3*2, y=min_loss+0.05, fontsize='medium', s=f'Min loss', color='#773344', ha='right', va='center')\n",
    "        plt.ylim((0,1))\n",
    "\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title(f'Loss on AE {n_qubit_autoencoder}->{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        exit()\n",
    "        plt.savefig(img_folder+f'/{n_qubit_autoencoder}_{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        # Info file \n",
    "        with open(img_folder+f'/info.txt','a') as file:\n",
    "            file.write(f'RUN INFORMATION\\nInput qubits={n_qubit_autoencoder}\\nTrash qubit={n_trash_qubit}\\nSeed={seed}\\nOptimizer=Optax.adam(stepsize={stepsize})\\nEpochs=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in batch_epochs.items()])}\\nBatch sizes={range_batches}\\nMin fidelity loss={min_loss}\\nDensity matrix rank={rank}\\nMin val loss found=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in min_val_found.items()])}\\nExec (training) time=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in batch_times.items()])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
