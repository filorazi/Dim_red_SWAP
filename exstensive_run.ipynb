{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer,AdagradOptimizer\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "from autoencoder import Autoencoder\n",
    "from autoencoder2 import Autoencoder_c11\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette =['#EABFCB','#C191A1','#A4508B','#5F0A87','#2F004F','#120021',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_qubit_autoencoder=list(range(2,8))\n",
    "range_batches = [10,20,50,100]\n",
    "seed=42\n",
    "epochs=150\n",
    "n=100\n",
    "stepsize=.2\n",
    "opt=AdamOptimizer(stepsize=.2)\n",
    "X=np.random.rand(n)*2*np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AE with 2 input qubit and 1 trash qubit in batches of 10\n",
      "the device has 4 qubits\n",
      "Epoch 150, Batch:9 Loss = 0.0060222635248934455\n",
      "--------------------------------------------------\n",
      "Running AE with 2 input qubit and 1 trash qubit in batches of 20\n",
      "the device has 4 qubits\n",
      "Epoch 150, Batch:4 Loss = 0.00060849215753782884\n",
      "--------------------------------------------------\n",
      "Running AE with 2 input qubit and 1 trash qubit in batches of 50\n",
      "the device has 4 qubits\n",
      "Epoch 47, Batch:1 Loss = 4.488236709976334e-066\n",
      "Early stop\n",
      "\n",
      "--------------------------------------------------\n",
      "Running AE with 2 input qubit and 1 trash qubit in batches of 100\n",
      "the device has 4 qubits\n",
      "Epoch 81, Batch:0 Loss = 9.931992301001058e-066\n",
      "Early stop\n",
      "\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 1 trash qubit in batches of 10\n",
      "the device has 5 qubits\n",
      "Epoch 150, Batch:9 Loss = 0.00554153115016294558\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 1 trash qubit in batches of 20\n",
      "the device has 5 qubits\n",
      "Epoch 150, Batch:4 Loss = 0.00462458892197852467\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 1 trash qubit in batches of 50\n",
      "the device has 5 qubits\n",
      "Epoch 53, Batch:1 Loss = 6.9913951662081695e-06\n",
      "Early stop\n",
      "\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 1 trash qubit in batches of 100\n",
      "the device has 5 qubits\n",
      "Epoch 98, Batch:0 Loss = 7.316626196253173e-065\n",
      "Early stop\n",
      "\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 2 trash qubit in batches of 10\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:9 Loss = 0.0257374382560131345\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 2 trash qubit in batches of 20\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:4 Loss = 0.0045894029614176575\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 2 trash qubit in batches of 50\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:1 Loss = 0.00071664080953547488\n",
      "--------------------------------------------------\n",
      "Running AE with 3 input qubit and 2 trash qubit in batches of 100\n",
      "the device has 6 qubits\n",
      "Epoch 107, Batch:0 Loss = 4.7542727597571495e-06\n",
      "Early stop\n",
      "\n",
      "--------------------------------------------------\n",
      "Running AE with 4 input qubit and 1 trash qubit in batches of 10\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:9 Loss = 0.01912131298413054745\n",
      "--------------------------------------------------\n",
      "Running AE with 4 input qubit and 1 trash qubit in batches of 20\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:4 Loss = 0.00061577770777257575\n",
      "--------------------------------------------------\n",
      "Running AE with 4 input qubit and 1 trash qubit in batches of 50\n",
      "the device has 6 qubits\n",
      "Epoch 150, Batch:1 Loss = 0.00065951801795383855\n",
      "--------------------------------------------------\n",
      "Running AE with 4 input qubit and 1 trash qubit in batches of 100\n",
      "the device has 6 qubits\n",
      "Epoch 37, Batch:0 Loss = 0.0011154164085000573\r"
     ]
    }
   ],
   "source": [
    "for n_qubit_autoencoder in range_qubit_autoencoder:\n",
    "    for n_trash_qubit in range(1,n_qubit_autoencoder):\n",
    "        batch_losses={}\n",
    "        batch_times={}\n",
    "        img_folder=f'runs/run_{n_qubit_autoencoder}to{n_qubit_autoencoder-n_trash_qubit}'\n",
    "        os.makedirs(img_folder,exist_ok=True)\n",
    "        for batch_size in range_batches:\n",
    "            folder=img_folder+f'/{batch_size}'\n",
    "            print(f\"Running AE with {n_qubit_autoencoder} input qubit and {n_trash_qubit} trash qubit in batches of {batch_size}\")\n",
    "            n_qubit=n_qubit_autoencoder+n_trash_qubit+1 \n",
    "            dvc = qml.device('default.qubit', wires=n_qubit, shots=None)\n",
    "            ae = Autoencoder_c11('c11',n_qubit_autoencoder,n_trash_qubit,dvc,seed)\n",
    "\n",
    "            start_time = time.time()\n",
    "            ae.train(X,opt,epochs,batch_size)\n",
    "            end_time = time.time()\n",
    "\n",
    "            os.makedirs(folder)\n",
    "            loss=ae.get_loss()\n",
    "            batch_losses[batch_size]=loss\n",
    "            batch_times[batch_size]=end_time-start_time\n",
    "            weights=ae.best_params()\n",
    "            np.save(folder+'/loss',np.array(loss))            \n",
    "            np.save(folder+'/weights',np.array(weights))\n",
    "\n",
    "        # Min loss\n",
    "        min_found= {a:min(batch_losses[a]) for a in range_batches }\n",
    "        min_loss =get_min_loss_fid(X,n_qubit_autoencoder,n_trash_qubit)\n",
    "\n",
    "        # Figure\n",
    "        plt.figure()\n",
    "        sns.set_palette(custom_palette)  \n",
    "        for b,r in zip(list(batch_losses.values()),range_batches):\n",
    "            sns.lineplot(x=range(len(b)),y=b,label=r)\n",
    "        plt.legend(title='Batch size')\n",
    "        plt.hlines(min_loss,0,epochs-1,color='#773344',linestyle='--')\n",
    "        plt.text(x=epochs//2, y=min_loss+0.05, fontsize='medium', s=f'Min loss', color='#773344', ha='right', va='center')\n",
    "        plt.ylim((0,1))\n",
    "\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title(f'Loss on AE {n_qubit_autoencoder}->{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        plt.savefig(img_folder+f'/{n_qubit_autoencoder}_{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        # Info file \n",
    "        with open(img_folder+f'/info.txt','a') as file:\n",
    "            file.write(f'RUN INFORMATION\\nInput qubits={n_qubit_autoencoder}\\nTrash qubit={n_trash_qubit}\\nSeed={seed}\\nOptimizer=AdamOptimizer(stepsize={opt.stepsize})\\nEpochs={epochs}\\nBatch sizes={range_batches}\\nMin fidelity loss={min_loss}\\nMin loss found=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in min_found.items()])}\\nExec (training) time=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in batch_times.items()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_update_accumulation',\n",
       " 'accumulation',\n",
       " 'apply_grad',\n",
       " 'beta1',\n",
       " 'beta2',\n",
       " 'compute_grad',\n",
       " 'eps',\n",
       " 'fm',\n",
       " 'reset',\n",
       " 'sm',\n",
       " 'step',\n",
       " 'step_and_cost',\n",
       " 'stepsize',\n",
       " 't']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(opt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
