{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer,AdagradOptimizer\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "from autoencoder import Autoencoder\n",
    "from autoencoder2 import Autoencoder_c11\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os \n",
    "from autoencoder3 import Autoencoder_composite\n",
    "from autoencoder5 import Autoencoder_autodecoder\n",
    "import time\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "from pennylane.optimize import AdamOptimizer,QNSPSAOptimizer\n",
    "from utils import *\n",
    "import os\n",
    "from EMCost import *\n",
    "from pennylane.math import reduce_dm\n",
    "from autoencoder6 import JAxutoencoder\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import optax \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette =[\n",
    "    # '#C24AA2','#D6518F',\n",
    "    '#EC5A77','#F57C73','#F69C6D','#F6BC66']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_qubit_autoencoder=[8]\n",
    "range_batches = [10,20,50,100]\n",
    "seed=42\n",
    "epochs=100 \n",
    "n=100\n",
    "stepsize=.2\n",
    "opt = optax.adam(stepsize)\n",
    "# X=np.random.rand(n)*np.pi/2\n",
    "\n",
    "X=list(range(n))\n",
    "random.shuffle(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AE with 8 input qubit and 2 trash qubit in batches of 10\n",
      "Epoch 19, \tBatch:2, \tTrain Loss = 0.017977, \tVal Loss = 0.015107"
     ]
    }
   ],
   "source": [
    "for n_qubit_autoencoder in range_qubit_autoencoder:\n",
    "    def get_input_state(p):\n",
    "        data=get_data(n_qubit_autoencoder)\n",
    "        return jnp.outer(data.ground_states[p], data.ground_states[p].conj())\n",
    "    X=[get_input_state(x) for x in X]\n",
    "\n",
    "    for n_trash_qubit in range(2,n_qubit_autoencoder):\n",
    "        train_batch_losses={}\n",
    "        val_batch_losses={}\n",
    "        batch_times={}\n",
    "        batch_epochs={}\n",
    "        img_folder=f'runs/run_{n_qubit_autoencoder}to{n_qubit_autoencoder-n_trash_qubit}'\n",
    "        os.makedirs(img_folder,exist_ok=True)\n",
    "        for batch_size in range_batches:\n",
    "            folder=img_folder+f'/{batch_size}'\n",
    "            print(f\"Running AE with {n_qubit_autoencoder} input qubit and {n_trash_qubit} trash qubit in batches of {batch_size}\")\n",
    "            n_qubit=n_qubit_autoencoder+n_trash_qubit\n",
    "            dvc = qml.device('default.mixed', wires=n_qubit, shots=None)\n",
    "            ae = JAxutoencoder(n_qubit_autoencoder,n_trash_qubit,dvc,'c11')\n",
    "            ae.set_layers(3)\n",
    "            start_time = time.time()\n",
    "            ae.train(X,opt,epochs,batch_size,val_split=.20)\n",
    "            end_time = time.time()\n",
    "\n",
    "            os.makedirs(folder)\n",
    "            train_loss,val_loss=ae.get_loss()\n",
    "            train_batch_losses[batch_size]=train_loss\n",
    "            val_batch_losses[batch_size]=val_loss\n",
    "            batch_times[batch_size]=end_time-start_time\n",
    "            batch_epochs[batch_size]=ae.get_final_epoch()\n",
    "            weights=ae.best_params()\n",
    "            np.save(folder+'/loss_train',np.array(train_loss))            \n",
    "            np.save(folder+'/loss_val',np.array(val_loss))            \n",
    "            np.save(folder+'/weights',np.array(weights))\n",
    "\n",
    "        # Min loss\n",
    "        min_val_found= {a:min(val_batch_losses[a]) for a in range_batches }\n",
    "        min_train_found= {a:min(train_batch_losses[a]) for a in range_batches }\n",
    "        min_loss,rank =get_min_loss_fid_ising(X,n_qubit_autoencoder,n_trash_qubit)\n",
    "\n",
    "        # Figure\n",
    "        plt.figure()\n",
    "        sns.set_palette(custom_palette)  \n",
    "        for a,b,c,d in zip(list(train_batch_losses.values()),list(val_batch_losses.values()),range_batches,custom_palette):\n",
    "            sns.lineplot(x=range(len(a)),y=a,label=f'train_{c}',color=d)\n",
    "            sns.lineplot(x=range(len(b)),y=[l.item() for l in b],label=f'val_{c}', color=d,linestyle=':')\n",
    "        plt.legend(title='Batch size')\n",
    "        # if len(epochs)>1:\n",
    "        #     plt.vlines(epochs[:-1],0,1,color='#C24AA2',linestyle='--')\n",
    "        #     plt.text(epochs[-1]-0.02, y=0.85, fontsize='medium', s=f'stage\\nchange', color='#973C7F', ha='center', va='center')\n",
    "\n",
    "        plt.hlines(min_loss,0,np.max(list(batch_epochs.values()))-1,color='#773344',linestyle='--')\n",
    "        plt.text(x=np.max(list(batch_epochs.values()))//3*2, y=min_loss+0.05, fontsize='medium', s=f'Min loss', color='#773344', ha='right', va='center')\n",
    "        plt.ylim((0,1))\n",
    "\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.title(f'Loss on AE {n_qubit_autoencoder}->{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        exit()\n",
    "        plt.savefig(img_folder+f'/{n_qubit_autoencoder}_{n_qubit_autoencoder-n_trash_qubit}')\n",
    "        # Info file \n",
    "        with open(img_folder+f'/info.txt','a') as file:\n",
    "            file.write(f'RUN INFORMATION\\nInput qubits={n_qubit_autoencoder}\\nTrash qubit={n_trash_qubit}\\nSeed={seed}\\nOptimizer=Optax.adam(stepsize={stepsize})\\nEpochs=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in batch_epochs.items()])}\\nBatch sizes={range_batches}\\nMin fidelity loss={min_loss}\\nDensity matrix rank={rank}\\nMin val loss found=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in min_val_found.items()])}\\nExec (training) time=\\n{''.join([f'\\t\\t\\t\\t{a}\\t:\\t{b}\\n' for a, b in batch_times.items()])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
